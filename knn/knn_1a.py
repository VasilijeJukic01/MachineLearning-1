# -*- coding: utf-8 -*-
"""kNN_1a.ipynb

Automatically generated by Colab.

"""

import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from matplotlib.colors import ListedColormap
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

data = pd.read_csv('iris.csv')
print(data)

label_encoder = LabelEncoder()
data['species'] = label_encoder.fit_transform(data['species'])

X = data[['sepal_length', 'sepal_width']]
y = data['species']

plt.plot(X['sepal_length'])
plt.plot(X['sepal_width'])
plt.show()

scaler = StandardScaler()
X.loc[:, 'sepal_length'] = scaler.fit_transform(X['sepal_length'].values.reshape(-1, 1))
X.loc[:, 'sepal_width'] = scaler.fit_transform(X['sepal_width'].values.reshape(-1, 1))

plt.plot(X['sepal_length'])
plt.plot(X['sepal_width'])
plt.show()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

class KNN:
    def __init__(self, classes_number, x, y, k, weighted=False):
        self.classes_number = classes_number
        self.X = x
        self.Y = y
        self.k = k
        self.weighted = weighted

    def accuracy(self, data):
        matches = 0

        for i in range(len(data['x'])):
            dists = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(self.X, data['x'][i])), axis=1))
            _, idxs = tf.nn.top_k(-dists, self.k)
            classes = tf.gather(self.Y, idxs)
            dists = tf.gather(dists, idxs)

            # Zero division fix
            epsilon = 1e-10
            if self.weighted:
                w = 1 / (dists + epsilon)
            else:
                w = tf.fill([self.k], 1/self.k)

            w_col = tf.reshape(w, (self.k, 1))
            classes_one_hot = tf.one_hot(classes, self.classes_number)
            scores = tf.reduce_sum(w_col * classes_one_hot, axis=0)

            h = tf.argmax(scores)
            actual = data['y'][i]

            mtch = (h == actual)
            if mtch:
              matches += 1
              if i % 5 == 0:
                  a = len(data['y'])
                  print(f'Test example: {i+1:2}/{a} | Predicted: {h} | Actual: {actual} | Match: {mtch}')

        acc = matches / len(data['x'])
        return acc


    def predict(self, data):
        predictions = []
        matches = 0

        for i in range(len(data['x'])):
            dists = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(self.X, data['x'][i])), axis=1))
            _, idxs = tf.nn.top_k(-dists, self.k)
            classes = tf.gather(self.Y, idxs)
            dists = tf.gather(dists, idxs)

            # Zero division fix
            epsilon = 1e-10
            if self.weighted:
                w = 1 / (dists + epsilon)
            else:
                w = tf.fill([self.k], 1/self.k)

            w_col = tf.reshape(w, (self.k, 1))
            classes_one_hot = tf.one_hot(classes, self.classes_number)
            scores = tf.reduce_sum(w_col * classes_one_hot, axis=0)

            h = tf.argmax(scores)
            predictions.append(h)

        return predictions

def plot_result(X, y, model, cmap_light=None, cmap_bold=None, xlabel='x', ylabel='y'):
    if cmap_light is None:
        cmap_light = ListedColormap(['#ffb282', '#93c0fa', '#d18ff7'])
    if cmap_bold is None:
        cmap_bold = ListedColormap(['#ff6200', '#076ced', '#a011f2'])

    x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1
    y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))

    Z = model.predict({'x': np.c_[xx.ravel(), yy.ravel()]})
    Z = np.array(Z).reshape(xx.shape)

    sns.set(style="whitegrid")

    plt.figure()
    plt.contourf(xx, yy, Z, alpha=0.8, cmap=cmap_light)

    sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, palette=cmap_bold.colors, edgecolor='k', s=100)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.title('KNN')
    plt.show()

knn = KNN(3, X_train, y_train, 3)
accuracy = knn.accuracy({'x': X_test.values, 'y': y_test.values})
print("Accuracy:", accuracy)

plot_result(X_test.values, y_test.values, knn)